{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbaa3ecb",
   "metadata": {},
   "source": [
    "# Fetal Health Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cbe83e",
   "metadata": {},
   "source": [
    "**Author: Victor Mayowa(MB;BS, Ilorin)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1e58ab",
   "metadata": {},
   "source": [
    "**Source: [Kaggle](https://www.kaggle.com/datasets/andrewmvd/fetal-health-classification)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8ecef3",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><a href=\"#title\">Title page</a><li>\n",
    "<li><a href=\"#toc\">Table of content</a><li>\n",
    "<li><a href=\"#abbreviation\">List of abbreviations</a><li>\n",
    "<li><a href=\"#abstract\">Summary</a><li>\n",
    "<li><a href=\"#background\">Background for the study</a><li>\n",
    "<li><a href=\"#aim\">Aims</a><li>\n",
    "<li><a href=\"#methodology\">Proposed methodology</a><li>\n",
    "<li><a href=\"#ethic\">Ethical considerations</a><li>\n",
    "<li><a href=\"#reference\">List of references</a><li>\n",
    "<li><a href=\"#appendix\">Appendices</a><li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e0763b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '_libgcc_mutex             0.1                 conda_forge    conda-forge' (from line 4 of module.txt)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r module.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b95a90",
   "metadata": {},
   "source": [
    "#### List of Abbreviation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dced1fe",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c214afe",
   "metadata": {},
   "source": [
    "#### Abstract\n",
    "Classify fetal health in order to prevent child and maternal mortality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15009d8",
   "metadata": {},
   "source": [
    "#### Context\n",
    "\n",
    "Reduction of child mortality is reflected in several of the United Nations' Sustainable Development Goals and is a key indicator of human progress.\n",
    "The UN expects that by 2030, countries end preventable deaths of newborns and children under 5 years of age, with all countries aiming to reduce underâ€‘5 mortality to at least as low as 25 per 1,000 live births.\n",
    "\n",
    "Parallel to notion of child mortality is of course maternal mortality, which accounts for **295 000 deaths** during and following pregnancy and childbirth (as of 2017). The vast majority of these deaths **(94%)** occurred in low-resource settings, and most could have been prevented.\n",
    "\n",
    "In light of what was mentioned above, **Cardiotocograms (CTGs)** are a simple and cost accessible option to assess fetal health, allowing healthcare professionals to take action in order to prevent child and maternal mortality. The equipment itself works by sending ultrasound pulses and reading its response, thus shedding light on fetal heart rate (FHR), fetal movements, uterine contractions and more.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe83ccb",
   "metadata": {},
   "source": [
    "#### Data Summary\n",
    "\n",
    "This dataset contains **2126 records** of features extracted from Cardiotocogram exams, which were then classified by three expert obstetritians into **3 classes:**\n",
    "\n",
    "* Normal\n",
    "* Suspect\n",
    "* Pathological"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec449084",
   "metadata": {},
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aa59523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install all required libraries\n",
    "#!pip install -U dataprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e11f1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ydata-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "626856b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.0.1-py3-none-win_amd64.whl (99.7 MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\asus\\anaconda3\\lib\\site-packages (from xgboost) (1.10.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\anaconda3\\lib\\site-packages (from xgboost) (1.24.0)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b5a426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "#from ydata_profiling import ProfileReport\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1230fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score, accuracy_score, classification_report, confusion_matrix, RocCurveDisplay, PrecisionRecallDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8593438",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fetal_health.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bfe82c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline value</th>\n",
       "      <th>accelerations</th>\n",
       "      <th>fetal_movement</th>\n",
       "      <th>uterine_contractions</th>\n",
       "      <th>light_decelerations</th>\n",
       "      <th>severe_decelerations</th>\n",
       "      <th>prolongued_decelerations</th>\n",
       "      <th>abnormal_short_term_variability</th>\n",
       "      <th>mean_value_of_short_term_variability</th>\n",
       "      <th>percentage_of_time_with_abnormal_long_term_variability</th>\n",
       "      <th>mean_value_of_long_term_variability</th>\n",
       "      <th>histogram_width</th>\n",
       "      <th>histogram_min</th>\n",
       "      <th>histogram_max</th>\n",
       "      <th>histogram_number_of_peaks</th>\n",
       "      <th>histogram_number_of_zeroes</th>\n",
       "      <th>histogram_mode</th>\n",
       "      <th>histogram_mean</th>\n",
       "      <th>histogram_median</th>\n",
       "      <th>histogram_variance</th>\n",
       "      <th>histogram_tendency</th>\n",
       "      <th>fetal_health</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>64.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>130.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>130.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132.0</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>117.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   baseline value  accelerations  fetal_movement  uterine_contractions  \\\n",
       "0           120.0          0.000             0.0                 0.000   \n",
       "1           132.0          0.006             0.0                 0.006   \n",
       "2           133.0          0.003             0.0                 0.008   \n",
       "3           134.0          0.003             0.0                 0.008   \n",
       "4           132.0          0.007             0.0                 0.008   \n",
       "\n",
       "   light_decelerations  severe_decelerations  prolongued_decelerations  \\\n",
       "0                0.000                   0.0                       0.0   \n",
       "1                0.003                   0.0                       0.0   \n",
       "2                0.003                   0.0                       0.0   \n",
       "3                0.003                   0.0                       0.0   \n",
       "4                0.000                   0.0                       0.0   \n",
       "\n",
       "   abnormal_short_term_variability  mean_value_of_short_term_variability  \\\n",
       "0                             73.0                                   0.5   \n",
       "1                             17.0                                   2.1   \n",
       "2                             16.0                                   2.1   \n",
       "3                             16.0                                   2.4   \n",
       "4                             16.0                                   2.4   \n",
       "\n",
       "   percentage_of_time_with_abnormal_long_term_variability  \\\n",
       "0                                               43.0        \n",
       "1                                                0.0        \n",
       "2                                                0.0        \n",
       "3                                                0.0        \n",
       "4                                                0.0        \n",
       "\n",
       "   mean_value_of_long_term_variability  histogram_width  histogram_min  \\\n",
       "0                                  2.4             64.0           62.0   \n",
       "1                                 10.4            130.0           68.0   \n",
       "2                                 13.4            130.0           68.0   \n",
       "3                                 23.0            117.0           53.0   \n",
       "4                                 19.9            117.0           53.0   \n",
       "\n",
       "   histogram_max  histogram_number_of_peaks  histogram_number_of_zeroes  \\\n",
       "0          126.0                        2.0                         0.0   \n",
       "1          198.0                        6.0                         1.0   \n",
       "2          198.0                        5.0                         1.0   \n",
       "3          170.0                       11.0                         0.0   \n",
       "4          170.0                        9.0                         0.0   \n",
       "\n",
       "   histogram_mode  histogram_mean  histogram_median  histogram_variance  \\\n",
       "0           120.0           137.0             121.0                73.0   \n",
       "1           141.0           136.0             140.0                12.0   \n",
       "2           141.0           135.0             138.0                13.0   \n",
       "3           137.0           134.0             137.0                13.0   \n",
       "4           137.0           136.0             138.0                11.0   \n",
       "\n",
       "   histogram_tendency  fetal_health  \n",
       "0                 1.0           2.0  \n",
       "1                 0.0           1.0  \n",
       "2                 0.0           1.0  \n",
       "3                 1.0           1.0  \n",
       "4                 1.0           1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1378e49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2126, 22)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01657514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2126 entries, 0 to 2125\n",
      "Data columns (total 22 columns):\n",
      " #   Column                                                  Non-Null Count  Dtype  \n",
      "---  ------                                                  --------------  -----  \n",
      " 0   baseline value                                          2126 non-null   float64\n",
      " 1   accelerations                                           2126 non-null   float64\n",
      " 2   fetal_movement                                          2126 non-null   float64\n",
      " 3   uterine_contractions                                    2126 non-null   float64\n",
      " 4   light_decelerations                                     2126 non-null   float64\n",
      " 5   severe_decelerations                                    2126 non-null   float64\n",
      " 6   prolongued_decelerations                                2126 non-null   float64\n",
      " 7   abnormal_short_term_variability                         2126 non-null   float64\n",
      " 8   mean_value_of_short_term_variability                    2126 non-null   float64\n",
      " 9   percentage_of_time_with_abnormal_long_term_variability  2126 non-null   float64\n",
      " 10  mean_value_of_long_term_variability                     2126 non-null   float64\n",
      " 11  histogram_width                                         2126 non-null   float64\n",
      " 12  histogram_min                                           2126 non-null   float64\n",
      " 13  histogram_max                                           2126 non-null   float64\n",
      " 14  histogram_number_of_peaks                               2126 non-null   float64\n",
      " 15  histogram_number_of_zeroes                              2126 non-null   float64\n",
      " 16  histogram_mode                                          2126 non-null   float64\n",
      " 17  histogram_mean                                          2126 non-null   float64\n",
      " 18  histogram_median                                        2126 non-null   float64\n",
      " 19  histogram_variance                                      2126 non-null   float64\n",
      " 20  histogram_tendency                                      2126 non-null   float64\n",
      " 21  fetal_health                                            2126 non-null   float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 365.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9cafe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fetal_health'] = [int(label - 1) for label in df['fetal_health']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e50e0b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "388dc054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2113, 22)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f8a24de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-3d1fed58b86b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1f4f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"fetal_health\", axis=1)\n",
    "y = data[\"fetal_health\"]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420f75c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection using SelectKBest\n",
    "k = 21  # Number of top features to select\n",
    "selector = SelectKBest(score_func=f_classif, k=k)\n",
    "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "# Train and evaluate a Random Forest classifier with SelectKBest\n",
    "rf_with_selectk = RandomForestClassifier(random_state=42)\n",
    "rf_with_selectk.fit(X_train_selected, y_train)\n",
    "y_pred_selectk = rf_with_selectk.predict(X_test_selected)\n",
    "accuracy_selectk = accuracy_score(y_test, y_pred_selectk)\n",
    "\n",
    "# Print results\n",
    "print(\"Accuracy with SelectKBest:\", accuracy_selectk)\n",
    "print(\"Classification Report with SelectKBest:\\n\", classification_report(y_test, y_pred_selectk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44249738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality Reduction using PCA\n",
    "# Try different values of n_components and evaluate performance\n",
    "for n_components in [10, 15, 20]:\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "    X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "    # Train and evaluate a Random Forest classifier with PCA\n",
    "    rf_with_pca = RandomForestClassifier(random_state=42)\n",
    "    rf_with_pca.fit(X_train_pca, y_train)\n",
    "    y_pred_pca = rf_with_pca.predict(X_test_pca)\n",
    "    accuracy_pca = accuracy_score(y_test, y_pred_pca)\n",
    "\n",
    "    # Print results for each value of n_components\n",
    "    print(f\"Accuracy with PCA (n_components={n_components}):\", accuracy_pca)\n",
    "    print(f\"Classification Report with PCA (n_components={n_components}):\\n\", classification_report(y_test, y_pred_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b024e0f2",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e958e858",
   "metadata": {},
   "source": [
    "#### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424f5694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902be52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install dask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634510a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from dataprep.eda import create_report, plot, plot_correlation, plot_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dcb400",
   "metadata": {},
   "source": [
    "#### Model development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d9e4ed",
   "metadata": {},
   "source": [
    "classifiers = dict(\n",
    "    k_nn=KNeighborsClassifier(n_neighbors=2), \n",
    "    mlp=MLPClassifier(alpha=1, max_iter=100),\n",
    "    svm=SVC(probability=True),\n",
    "    random_forest=RandomForestClassifier(random_state=42),\n",
    "    gradientboost=GradientBoostingClassifier(),\n",
    "    adaboost=AdaBoostClassifier(),\n",
    "    xgboost=XGBClassifier(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7737fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'SVC': SVC(),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'Bagging': BaggingClassifier(),\n",
    "    'GradientBoost': GradientBoostingClassifier(),\n",
    "    'XGBClassifier': XGBClassifier(),\n",
    "    'MLP': MLPClassifier()\n",
    "}\n",
    "\n",
    "# Define the hyperparameters for each classifier\n",
    "parameters = {\n",
    "    'SVC': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
    "    'RandomForest': {'n_estimators': [50, 100, 200], 'max_depth': [None, 5, 10]},\n",
    "    'AdaBoost': {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1]},\n",
    "    'Bagging': {'n_estimators': [50, 100, 200], 'max_samples': [0.5, 1.0]},\n",
    "    'GradientBoost': {'n_estimators': [100, 200], 'learning_rate': [1e-1, 5e-2, 1e-2, 5e-3], 'max_depth': [3, 4, 5]},\n",
    "    'XGBClassifier': {'booster': ['gbtree', 'gblinear', 'dart'], 'eta': [0.1, 0.2, 0.3, 0.4], 'alpha': [0.1, 0.2, 0.3, 0.4, 0.6]},\n",
    "    'MLP': {'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "            'activation': ['tanh', 'relu'],\n",
    "            'solver': ['sgd', 'adam'],\n",
    "            'alpha': [0.0001, 0.05],\n",
    "            'learning_rate': ['constant','adaptive']}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efd2000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, fbeta_score, f1_score, accuracy_score\n",
    "\n",
    "# Assuming you have already performed the GridSearchCV and have the results\n",
    "\n",
    "# Define a list of classifier names\n",
    "classifier_names = ['SVC', 'RandomForest', 'AdaBoost', 'Bagging', 'GradientBoost', 'MLP', 'XGBClassifier']\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Classifier', 'Metric', 'Value'])\n",
    "metrics = ['Precision', 'Recall', 'F-beta Score', 'F1 Score', 'Accuracy']\n",
    "\n",
    "# Iterate through classifiers and get evaluation metrics\n",
    "for classifier_name, classifier in classifiers.items():\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    fbeta = fbeta_score(y_test, y_pred, beta=1, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    metrics_values = [precision, recall, fbeta, f1, accuracy]\n",
    "    \n",
    "    # Create a DataFrame for the current classifier's metrics\n",
    "    classifier_df = pd.DataFrame({\n",
    "        'Classifier': [classifier_name]*len(metrics),\n",
    "        'Metric': metrics,\n",
    "        'Value': metrics_values\n",
    "    })\n",
    "    \n",
    "    # Append the classifier's metrics to the results DataFrame\n",
    "    results_df = pd.concat([results_df, classifier_df], axis=0)\n",
    "\n",
    "# Set multi-index for precision and recall\n",
    "results_df.set_index(['Classifier', 'Metric'], inplace=True)\n",
    "\n",
    "# Display the results DataFrame\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167134aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_grid_parameters = {\n",
    "    SVC(): {\n",
    "        'C': [0.0005, 0.001, 0.002, 0.01, 0.1, 1, 10],\n",
    "        'gamma': [0.001, 0.01, 0.1, 1],\n",
    "        'kernel': ['rbf', 'poly', 'sigmoid']\n",
    "    },\n",
    "    RandomForestClassifier(): {\n",
    "        'n_estimators': [10, 40, 70, 100],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'min_samples_split': [0.2, 0.5, 0.7, 2],\n",
    "        'min_samples_leaf': [0.2, 0.5, 1, 2],\n",
    "        'max_features': [0.2, 0.5, 1, 2],\n",
    "    },\n",
    "    AdaBoostClassifier(): {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 1]\n",
    "    },\n",
    "    BaggingClassifier(): {\n",
    "        'n_estimators': [10, 30, 50, 60],\n",
    "        'max_samples': [0.1, 0.3, 0.5, 0.8, 1.],\n",
    "        'max_features': [0.2, 0.5, 1, 2],\n",
    "    },\n",
    "    DecisionTreeClassifier(): {\n",
    "        'max_depth': [3, 5, 7, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "    },\n",
    "    GradientBoostingClassifier(): {},\n",
    "    MLPClassifier(): {\n",
    "        'hidden_layer_sizes': [(200,), (300,), (400,), (128, 128), (256, 256)],\n",
    "        'alpha': [0.001, 0.005, 0.01, 1.],\n",
    "        'batch_size': [128, 256, 512, 1024],\n",
    "        'learning_rate': ['constant', 'adaptive'],\n",
    "        'max_iter': [100, 200, 300, 400, 500]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5552a823",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['precision', 'recall', 'fbeta_score', 'accuracy']\n",
    "res = np.empty((len(classifiers), len(metrics)*3+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0006438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15246da",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0652e819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classifiers and their respective hyperparameters\n",
    "classifiers = {\n",
    "    'SVC': SVC(),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'Bagging': BaggingClassifier(),\n",
    "    'GradientBoost': GradientBoostingClassifier(),\n",
    "    'MLP': MLPClassifier()\n",
    "}\n",
    "\n",
    "# Define the hyperparameters for each classifier\n",
    "parameters = {\n",
    "    'SVC': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
    "    'RandomForest': {'n_estimators': [50, 100, 200], 'max_depth': [None, 5, 10]},\n",
    "    'AdaBoost': {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1]},\n",
    "    'Bagging': {'n_estimators': [50, 100, 200], 'max_samples': [0.5, 1.0]},\n",
    "    'GradientBoost': {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1], 'max_depth': [3, 4, 5]},\n",
    "    'MLP': {'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "            'activation': ['tanh', 'relu'],\n",
    "            'solver': ['sgd', 'adam'],\n",
    "            'alpha': [0.0001, 0.05],\n",
    "            'learning_rate': ['constant','adaptive']}\n",
    "}\n",
    "\n",
    "# Iterate through classifiers and perform GridSearchCV\n",
    "for classifier_name, classifier in classifiers.items():\n",
    "    print(f\"Grid Search for {classifier_name}:\")\n",
    "    grid_search = GridSearchCV(classifier, parameters[classifier_name], cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best Cross-validated Score: {grid_search.best_score_}\")\n",
    "    print(f\"Test Accuracy: {grid_search.score(X_test, y_test)}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce688a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(self, classifier, params, n_jobs=2, verbose=1):\n",
    "        \"\"\"\n",
    "        Performs GridSearchCV on `params` passed on the `self.model`\n",
    "        And returns the tuple: (best_estimator, best_params, best_score).\n",
    "        \"\"\"\n",
    "        score = accuracy_score\n",
    "        grid = GridSearchCV(estimator=classifier, param_grid=params, scoring=make_scorer(score), n_jobs=n_jobs, verbose=verbose, cv=3)\n",
    "        grid_result = grid.fit(self.X_train, self.y_train)\n",
    "        y_pred = grid.predict(self.X_test)\n",
    "        accuracy = accuracy_score(y_true=self.y_test, y_pred=y_pred)\n",
    "        print(\"Grid Search Accuracy: {:.2f}%\".format(accuracy*100))\n",
    "        return grid_result.best_estimator_, grid_result.best_params_, grid_result.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ef6e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    " def set_best_estimators(self):\n",
    "        # emotion classes you want to perform grid search on\n",
    "        emotions = [\"sad\",\"fear\",\"neutral\",\"angry\",\"happy\",\"disgust\",\"ps\"]\n",
    "        # number of parallel jobs during the grid search\n",
    "        n_jobs = 4\n",
    "        best_estimators = []\n",
    "        for model, params in classification_grid_parameters.items():\n",
    "            if model.__class__.__name__ == \"KNeighborsClassifier\":\n",
    "                params['n_neighbors'] = [len(emotions)]\n",
    "        best_estimator, best_params, cv_best_score = self.grid_search(model, params=params, n_jobs=n_jobs)\n",
    "        best_estimators.append((best_estimator, best_params, cv_best_score))\n",
    "        print(f\"{emotions} {best_estimator.__class__.__name__} achieved {cv_best_score:.3f} cross validation accuracy score!\")\n",
    "        pickle.dump(best_estimators, open(f\"best_classifiers.pickle\", \"wb\"))\n",
    "        return best_estimators\n",
    "\n",
    "    def get_best_estimators(self):\n",
    "        \"\"\"\n",
    "        Loads the estimators that are pickled in `grid` folder\n",
    "        Note that if you want to use different or more estimators,\n",
    "        you can fine tune the parameters in `grid_search function\"\n",
    "        and run it again ( may take hours )\n",
    "        \"\"\"\n",
    "\n",
    "        if os.path.exists(\"best_classifiers.pickle\"):\n",
    "            df = pd.read_pickle('best_classifiers.pickle')\n",
    "            print(df)\n",
    "            best_estimators = pickle.load(open(\"best_classifiers.pickle\", \"rb\"))\n",
    "        else:\n",
    "            best_estimators = self.set_best_estimators()\n",
    "\n",
    "        return best_estimators\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a1f5ce",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f77964",
   "metadata": {},
   "source": [
    "#### Model saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177c2ed6",
   "metadata": {},
   "source": [
    "#### Model Deployment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
