{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbaa3ecb",
   "metadata": {},
   "source": [
    "# Fetal Health Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cbe83e",
   "metadata": {},
   "source": [
    "**Author: Victor Mayowa(MB;BS, Ilorin)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1e58ab",
   "metadata": {},
   "source": [
    "**Source: [Kaggle](https://www.kaggle.com/datasets/andrewmvd/fetal-health-classification)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8ecef3",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><a href=\"#title\">Title page</a><li>\n",
    "<li><a href=\"#toc\">Table of content</a><li>\n",
    "<li><a href=\"#abbreviation\">List of abbreviations</a><li>\n",
    "<li><a href=\"#abstract\">Summary</a><li>\n",
    "<li><a href=\"#background\">Background for the study</a><li>\n",
    "<li><a href=\"#aim\">Aims</a><li>\n",
    "<li><a href=\"#methodology\">Proposed methodology</a><li>\n",
    "<li><a href=\"#ethic\">Ethical considerations</a><li>\n",
    "<li><a href=\"#reference\">List of references</a><li>\n",
    "<li><a href=\"#appendix\">Appendices</a><li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b95a90",
   "metadata": {},
   "source": [
    "#### List of Abbreviation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dced1fe",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c214afe",
   "metadata": {},
   "source": [
    "#### Abstract\n",
    "Classify fetal health in order to prevent child and maternal mortality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15009d8",
   "metadata": {},
   "source": [
    "#### Context\n",
    "\n",
    "Reduction of child mortality is reflected in several of the United Nations' Sustainable Development Goals and is a key indicator of human progress.\n",
    "The UN expects that by 2030, countries end preventable deaths of newborns and children under 5 years of age, with all countries aiming to reduce underâ€‘5 mortality to at least as low as 25 per 1,000 live births.\n",
    "\n",
    "Parallel to notion of child mortality is of course maternal mortality, which accounts for **295 000 deaths** during and following pregnancy and childbirth (as of 2017). The vast majority of these deaths **(94%)** occurred in low-resource settings, and most could have been prevented.\n",
    "\n",
    "In light of what was mentioned above, **Cardiotocograms (CTGs)** are a simple and cost accessible option to assess fetal health, allowing healthcare professionals to take action in order to prevent child and maternal mortality. The equipment itself works by sending ultrasound pulses and reading its response, thus shedding light on fetal heart rate (FHR), fetal movements, uterine contractions and more.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe83ccb",
   "metadata": {},
   "source": [
    "#### Data Summary\n",
    "\n",
    "This dataset contains **2126 records** of features extracted from Cardiotocogram exams, which were then classified by three expert obstetritians into **3 classes:**\n",
    "\n",
    "* Normal\n",
    "* Suspect\n",
    "* Pathological"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec449084",
   "metadata": {},
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aa59523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install all required libraries\n",
    "#!pip install -U dataprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e11f1d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b5a426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1230fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score, confusion_matrix, RocCurveDisplay, PrecisionRecallDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8593438",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fetal_health.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bfe82c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline value</th>\n",
       "      <th>accelerations</th>\n",
       "      <th>fetal_movement</th>\n",
       "      <th>uterine_contractions</th>\n",
       "      <th>light_decelerations</th>\n",
       "      <th>severe_decelerations</th>\n",
       "      <th>prolongued_decelerations</th>\n",
       "      <th>abnormal_short_term_variability</th>\n",
       "      <th>mean_value_of_short_term_variability</th>\n",
       "      <th>percentage_of_time_with_abnormal_long_term_variability</th>\n",
       "      <th>mean_value_of_long_term_variability</th>\n",
       "      <th>histogram_width</th>\n",
       "      <th>histogram_min</th>\n",
       "      <th>histogram_max</th>\n",
       "      <th>histogram_number_of_peaks</th>\n",
       "      <th>histogram_number_of_zeroes</th>\n",
       "      <th>histogram_mode</th>\n",
       "      <th>histogram_mean</th>\n",
       "      <th>histogram_median</th>\n",
       "      <th>histogram_variance</th>\n",
       "      <th>histogram_tendency</th>\n",
       "      <th>fetal_health</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>64.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>130.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>130.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132.0</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>117.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   baseline value  accelerations  fetal_movement  uterine_contractions  \\\n",
       "0           120.0          0.000             0.0                 0.000   \n",
       "1           132.0          0.006             0.0                 0.006   \n",
       "2           133.0          0.003             0.0                 0.008   \n",
       "3           134.0          0.003             0.0                 0.008   \n",
       "4           132.0          0.007             0.0                 0.008   \n",
       "\n",
       "   light_decelerations  severe_decelerations  prolongued_decelerations  \\\n",
       "0                0.000                   0.0                       0.0   \n",
       "1                0.003                   0.0                       0.0   \n",
       "2                0.003                   0.0                       0.0   \n",
       "3                0.003                   0.0                       0.0   \n",
       "4                0.000                   0.0                       0.0   \n",
       "\n",
       "   abnormal_short_term_variability  mean_value_of_short_term_variability  \\\n",
       "0                             73.0                                   0.5   \n",
       "1                             17.0                                   2.1   \n",
       "2                             16.0                                   2.1   \n",
       "3                             16.0                                   2.4   \n",
       "4                             16.0                                   2.4   \n",
       "\n",
       "   percentage_of_time_with_abnormal_long_term_variability  \\\n",
       "0                                               43.0        \n",
       "1                                                0.0        \n",
       "2                                                0.0        \n",
       "3                                                0.0        \n",
       "4                                                0.0        \n",
       "\n",
       "   mean_value_of_long_term_variability  histogram_width  histogram_min  \\\n",
       "0                                  2.4             64.0           62.0   \n",
       "1                                 10.4            130.0           68.0   \n",
       "2                                 13.4            130.0           68.0   \n",
       "3                                 23.0            117.0           53.0   \n",
       "4                                 19.9            117.0           53.0   \n",
       "\n",
       "   histogram_max  histogram_number_of_peaks  histogram_number_of_zeroes  \\\n",
       "0          126.0                        2.0                         0.0   \n",
       "1          198.0                        6.0                         1.0   \n",
       "2          198.0                        5.0                         1.0   \n",
       "3          170.0                       11.0                         0.0   \n",
       "4          170.0                        9.0                         0.0   \n",
       "\n",
       "   histogram_mode  histogram_mean  histogram_median  histogram_variance  \\\n",
       "0           120.0           137.0             121.0                73.0   \n",
       "1           141.0           136.0             140.0                12.0   \n",
       "2           141.0           135.0             138.0                13.0   \n",
       "3           137.0           134.0             137.0                13.0   \n",
       "4           137.0           136.0             138.0                11.0   \n",
       "\n",
       "   histogram_tendency  fetal_health  \n",
       "0                 1.0           2.0  \n",
       "1                 0.0           1.0  \n",
       "2                 0.0           1.0  \n",
       "3                 1.0           1.0  \n",
       "4                 1.0           1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1378e49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2126, 22)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1093331f",
   "metadata": {},
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "class HDCClassifier:\n",
    "    def __init__(self, n_classes, n_features, D):\n",
    "        self.n_classes = n_classes\n",
    "        self.n_features = n_features\n",
    "        self.D = D\n",
    "        self.classes = torch.zeros(n_classes, D)\n",
    "        self.base_vector = torch.randn(D, n_features)\n",
    "        \n",
    "    def create_base_vector(self):\n",
    "        self.base_vector = torch.randn(self.D, self.n_features)\n",
    "    \n",
    "    def encode_data(self, data):\n",
    "        encoded_data = torch.matmul(data, self.base_vector.T)\n",
    "        return encoded_data\n",
    "    \n",
    "    def train(self, data, labels, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            for i, encoded_sample in enumerate(data):\n",
    "                predicted_class = self.predict(encoded_sample)\n",
    "                true_class = labels[i]\n",
    "                \n",
    "                if predicted_class != true_class:\n",
    "                    self.classes[true_class] += learning_rate * encoded_sample\n",
    "                    self.classes[predicted_class] -= learning_rate * encoded_sample\n",
    "                    \n",
    "    def predict(self, encoded_sample):\n",
    "        scores = torch.matmul(self.classes, encoded_sample)\n",
    "        predicted_class = torch.argmax(scores)\n",
    "        return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e688e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDCClassifier:\n",
    "    def __init__(self, n_features, D):\n",
    "        self.n_features = n_features\n",
    "        self.D = D\n",
    "        self.base_vector = torch.randn(D, n_features)\n",
    "        self.classes = None\n",
    "    \n",
    "    def create_base_vector(self):\n",
    "        self.base_vector = torch.randn(self.D, self.n_features)\n",
    "    \n",
    "    def encode_data(self, data):\n",
    "        encoded_data = torch.matmul(data, self.base_vector.T)\n",
    "        return encoded_data\n",
    "    \n",
    "    def train(self, data, labels, epochs, learning_rate):\n",
    "        # Determine the number of classes dynamically\n",
    "        n_classes = len(torch.unique(labels))\n",
    "        self.classes = torch.zeros(n_classes, self.D)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            for i, encoded_sample in enumerate(data):\n",
    "                predicted_class = self.predict(encoded_sample)\n",
    "                true_class = labels[i]\n",
    "                \n",
    "                if predicted_class != true_class:\n",
    "                    self.classes[true_class] += learning_rate * encoded_sample\n",
    "                    self.classes[predicted_class] -= learning_rate * encoded_sample\n",
    "\n",
    "    def predict(self, encoded_sample):\n",
    "        scores = torch.matmul(self.classes, encoded_sample)\n",
    "        predicted_class = torch.argmax(scores)\n",
    "        return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbb64658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetal=HDCClassifier(n_classes=3,n_features=21, D=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9cafe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fetal_health'] = [int(label - 1) for label in df['fetal_health']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e1f4f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"fetal_health\"])\n",
    "y = df[\"fetal_health\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f88611e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3b85cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "# Convert float labels to integers\n",
    "y_train_int = y_train.astype(int)\n",
    "y_test_int = y_test.astype(int)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.values).float()\n",
    "X_test_tensor = torch.tensor(X_test.values).float()\n",
    "y_train_tensor = torch.tensor(y_train_int.values).long()\n",
    "y_test_tensor = torch.tensor(y_test_int.values).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420f75c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76015ce1",
   "metadata": {},
   "source": [
    "# Initialize HDCClassifier\n",
    "n_classes = len(y.unique())\n",
    "n_features = X_train.shape[1]\n",
    "D = 100  # Choose an appropriate hyperdimensional space size\n",
    "learning_rate = 0.1  # Choose an appropriate learning rate\n",
    "hdc_classifier = HDCClassifier(n_features, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faa3698",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa5f4f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fad24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding data\n",
    "encoded_X_train = hdc_classifier.encode_data(X_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dd1851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "epochs = 50  # Choose the number of training epochs\n",
    "hdc_classifier.train(encoded_X_train, y_train_tensor, epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d206c96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding test data and predicting\n",
    "encoded_X_test = hdc_classifier.encode_data(X_test_tensor)\n",
    "predicted_labels = [hdc_classifier.predict(encoded_sample) for encoded_sample in encoded_X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9e1051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = sum(predicted_labels == y_test_tensor.numpy()) / len(y_test_tensor)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b024e0f2",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e958e858",
   "metadata": {},
   "source": [
    "#### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902be52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install dask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634510a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dataprep.eda import create_report, plot, plot_correlation, plot_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dcb400",
   "metadata": {},
   "source": [
    "#### Model development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a1f5ce",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f77964",
   "metadata": {},
   "source": [
    "#### Model saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177c2ed6",
   "metadata": {},
   "source": [
    "#### Model Deployment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
